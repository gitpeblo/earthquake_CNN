{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lc7UGQdGDa26"
   },
   "source": [
    "# Earthquake\n",
    "\n",
    "Create a simple Decoder for the Earthquake data.\n",
    "\n",
    "/ HYSTORY / -----------------------------------------------------------------\n",
    "\n",
    "2025/06/05: v0 (from Decoder_mock_v0) /\n",
    "\n",
    "2025/06/06: v0_1 /\n",
    "- Corrected: Using preprocessed data with correct sorting of rows (bottom-to-top)\n",
    "\n",
    "/ NOTES / -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Current path ---------------------------------------------------------------\n",
    "script_path = str(Path().absolute())\n",
    "print('Current path:', script_path)\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Results folder -------------------------------------------------------------\n",
    "path_results = script_path + \"/results\"\n",
    "# folder where the current run's results shall be nested in\n",
    "\n",
    "if not os.path.exists(path_results):\n",
    "    os.makedirs(path_results)\n",
    "    print('Folder \"%s\" created.' % os.path.basename(path_results))\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Imported data folder -------------------------------------------------------\n",
    "path_data = script_path + \"/data\"\n",
    "# folder inside which the preprocessed data will be copied\n",
    "\n",
    "if not os.path.exists(path_data):\n",
    "    os.makedirs(path_data)\n",
    "    print('Folder \"%s\" created.' % os.path.basename(path_data))\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# keep it quiet, jeez!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    \n",
    "    # For cudnn backend\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Desired device:', device)\n",
    "\n",
    "print(torch.cuda.is_available())        # Should return True\n",
    "print(torch.cuda.current_device())      # Should not raise an error\n",
    "print(torch.cuda.get_device_name(0))    # Should show RTX 4090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DLF5Q9vdmHI"
   },
   "source": [
    "# Utils\n",
    "\n",
    "## condition_vector_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "def condition_vector_to_df(cond_vector: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Decode a conditioning vector into a single-row DataFrame with named columns.\n",
    "    Supports formats with or without POV one-hot columns (POV_A, POV_B, POV_C).\n",
    "    Issues a warning if the vector length is unexpected.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define expected column structures\n",
    "    base_fields = [\"length\", \"width\", \"height\", \"thickness\", \"r\", \"c\", \"PGA\", \"Hz\"]\n",
    "    pov_fields = [\"POV_A\", \"POV_B\", \"POV_C\"]\n",
    "\n",
    "    if len(cond_vector) == len(base_fields) + len(pov_fields):  # 11\n",
    "        columns = base_fields + pov_fields\n",
    "    elif len(cond_vector) == len(base_fields):  # 8\n",
    "        columns = base_fields\n",
    "    else:\n",
    "        warnings.warn(f\"Unexpected conditioning vector length: {len(cond_vector)}. \"\n",
    "                      f\"Expected 8 or 11.\")\n",
    "        columns = [f\"param_{i}\" for i in range(len(cond_vector))]\n",
    "\n",
    "    # Format values\n",
    "    data = {}\n",
    "    for i, col in enumerate(columns):\n",
    "        val = cond_vector[i]\n",
    "        if col.startswith(\"POV_\"):\n",
    "            data[col] = int(round(val))  # always keep as int\n",
    "        else:\n",
    "            data[col] = float(val)       # everything else as float\n",
    "\n",
    "    return pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display_vector_and_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def display_vector_and_image(img_tensor, condition_vector, image_name=None):\n",
    "    \"\"\"\n",
    "    Display decoded conditioning vector alongside the corresponding image.\n",
    "    Accepts an image tensor (C, H, W) and a condition vector (numpy).\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tensor to numpy image, handling both grayscale and RGB\n",
    "    if img_tensor.ndim == 3 and img_tensor.shape[0] in [1, 3]:\n",
    "        img = img_tensor.permute(1, 2, 0).numpy()  # C, H, W â†’ H, W, C\n",
    "        if img.shape[2] == 1:\n",
    "            img = img.squeeze(-1)  # Convert (H, W, 1) to (H, W) for grayscale\n",
    "    else:\n",
    "        img = img_tensor.numpy()\n",
    "    \n",
    "    # Create base DataFrame from condition vector\n",
    "    df = condition_vector_to_df(condition_vector)\n",
    "\n",
    "    # Format originally integer columns to remove trailing .0 when printing\n",
    "    int_like_cols = [\"length\", \"width\", \"height\", \"thickness\", \"r\", \"c\", \"POV\"]\n",
    "    one_hot_cols = [\"POV_A\", \"POV_B\", \"POV_C\"]\n",
    "    for col in int_like_cols + one_hot_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: f\"{float(x):g}\" if isinstance(x, (int, float)) and float(x).is_integer() else x\n",
    "            )\n",
    "\n",
    "    # Add image name as a new first column (with the same value for all columns)\n",
    "    df.insert(0, \"Image\", [image_name] * len(df))\n",
    "\n",
    "    # Display with left-aligned headers and no index\n",
    "    styled_df = df.style.set_table_styles(\n",
    "        [{\"selector\": \"th\", \"props\": [(\"text-align\", \"left\")]}]\n",
    "    ).set_properties(**{\"text-align\": \"left\"}).hide(axis=\"index\")\n",
    "    display(styled_df)\n",
    "\n",
    "    # Show image\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    ax.imshow(img, origin='upper', cmap='magma' if img.ndim == 2 else None)\n",
    "    ax.set_xlabel(\"x [pixels]\")\n",
    "    ax.set_ylabel(\"y [pixels]\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def visualize_sample(X_i, y_i, yhat_i, idx=None, image_names=None, epoch=None):\n",
    "    \"\"\"\n",
    "    - Print decoded info using `condition_vector_to_df`\n",
    "    - Plot the real vs generated image\n",
    "    - If `idx` and `image_names` are provided, shows image name in DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Decode and display the condition info\n",
    "    df = condition_vector_to_df(X_i.clone().detach().cpu().numpy())\n",
    "\n",
    "    # Add image name if available\n",
    "    if idx is not None and image_names is not None:\n",
    "        image_name = image_names[idx]\n",
    "        df.insert(0, \"Image\", [image_name] * len(df))\n",
    "    else:\n",
    "        image_name = None  # for consistent use below\n",
    "    \n",
    "    # Display DataFrame\n",
    "    styled_df = df.style.set_table_styles(\n",
    "        [{\"selector\": \"th\", \"props\": [(\"text-align\", \"left\")]}]\n",
    "    ).set_properties(**{\"text-align\": \"left\"}).hide(axis=\"index\")\n",
    "    display(styled_df)\n",
    "\n",
    "    # Convert tensors to NumPy\n",
    "    y_i_np    = y_i.clone().detach().cpu().numpy()\n",
    "    yhat_i_np = yhat_i.clone().detach().cpu().numpy()\n",
    "\n",
    "    # If RGB, reshape from (C, H, W) to (H, W, C)\n",
    "    if y_i_np.ndim == 3 and y_i_np.shape[0] == 3:\n",
    "        y_i_np    = np.transpose(y_i_np, (1, 2, 0))\n",
    "        yhat_i_np = np.transpose(yhat_i_np, (1, 2, 0))\n",
    "        is_rgb = True\n",
    "    else:\n",
    "        y_i_np    = y_i_np.squeeze()\n",
    "        yhat_i_np = yhat_i_np.squeeze()\n",
    "        is_rgb = False\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "    if epoch is not None:\n",
    "        fig.suptitle(f\"Epoch {epoch}\", y=0.95)\n",
    "\n",
    "    axes[0].set_title(\"$y$\")\n",
    "    if is_rgb:\n",
    "        cbar0 = axes[0].imshow(y_i_np, origin='upper')\n",
    "    else:\n",
    "        cbar0 = axes[0].imshow(y_i_np, cmap='magma', origin='upper', vmin=y_i_np.min(), vmax=y_i_np.max())\n",
    "\n",
    "    axes[1].set_title(\"$\\hat{y}$\")\n",
    "    if is_rgb:\n",
    "        cbar1 = axes[1].imshow(yhat_i_np, origin='upper')\n",
    "    else:\n",
    "        cbar1 = axes[1].imshow(yhat_i_np, cmap='magma', origin='upper', vmin=y_i_np.min(), vmax=y_i_np.max())\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"x [pixels]\")\n",
    "        ax.set_ylabel(\"y [pixels]\")\n",
    "\n",
    "    # Overlay\n",
    "    axes[2].set_title(\"Overlay\")\n",
    "    if is_rgb:\n",
    "        cbar2 = axes[2].imshow(yhat_i_np, origin='upper')\n",
    "        z_contour = np.mean(y_i_np, axis=2)  # simple luminance projection\n",
    "    else:\n",
    "        cbar2 = axes[2].imshow(yhat_i_np, cmap='magma', origin='upper', vmin=y_i_np.min(), vmax=y_i_np.max())\n",
    "        z_contour = y_i_np\n",
    "\n",
    "    axes[2].contour(z_contour, colors='white', levels=5, linewidths=0.5)\n",
    "\n",
    "    # Add colorbars (only if grayscale)\n",
    "    if not is_rgb:\n",
    "        fig.colorbar(cbar0, ax=axes[0], orientation='vertical', shrink=0.35, aspect=10)\n",
    "        fig.colorbar(cbar1, ax=axes[1], orientation='vertical', shrink=0.35, aspect=10)\n",
    "        fig.colorbar(cbar2, ax=axes[2], orientation='vertical', shrink=0.35, aspect=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history['epoch'], history['loss_train'], c='C0', lw=1, label='train')\n",
    "    plt.plot(history['epoch'], history['loss_valid'], c='C1', lw=1, label='valid')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim([0, None])\n",
    "    plt.title('Loss History')\n",
    "    plt.legend(loc='upper left', ncol=2)\n",
    "    plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)\n",
    "    plt.pause(0.1)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgQOXVlgDW6C"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source and destination base paths\n",
    "path_preprocessed = os.path.abspath(os.path.join(\"..\", \"prepare_data\", \"results\"))\n",
    "folders_preprocessed = [\"Output 1\", \"Output 2\", \"Output 3\", \"Output 4\"]\n",
    "\n",
    "for folder in folders_preprocessed:\n",
    "# debug: for folder in [\"Output 1\"]:\n",
    "    src_folder = os.path.join(path_preprocessed, folder)\n",
    "    dst_folder = os.path.join(path_data, folder)\n",
    "\n",
    "    # Create destination folder if it doesn't exist\n",
    "    os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "    for subfolder_name in os.listdir(src_folder):\n",
    "    # debug: for subfolder_name in os.listdir(src_folder)[:2]:\n",
    "        subfolder_path = os.path.join(src_folder, subfolder_name)\n",
    "        if os.path.isdir(subfolder_path) and subfolder_name.startswith(\"DesignPoint\") and len(subfolder_name) > len(\"DesignPoint\"):\n",
    "            # Extract letter and zero-padded number\n",
    "            design_letter = subfolder_name[len(\"DesignPoint\")]\n",
    "            design_number = ''.join(filter(str.isdigit, subfolder_name))\n",
    "            padded_number = design_number.zfill(4)\n",
    "\n",
    "            prefix = f\"DP_{design_letter}_{padded_number}\"\n",
    "\n",
    "            valid_files = [\n",
    "                file_name for file_name in os.listdir(subfolder_path)\n",
    "                if file_name.startswith(\"06_valid\")\n",
    "            ]\n",
    "            \n",
    "            for file_name in valid_files:\n",
    "                new_file_name = file_name.replace(\"06_valid\", \"bay\")\n",
    "                dst_file_name = f\"{prefix}_{new_file_name}\"\n",
    "                src_file = os.path.join(subfolder_path, file_name)\n",
    "                dst_file = os.path.join(dst_folder, dst_file_name)\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "\n",
    "print(\"Data imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare conditioning vectors\n",
    "\n",
    "This happens in 2 steps:\n",
    "1. We re-arrange the excel file, checking that each existing image corresponds to the value in the \"Design point\" column\n",
    "2. We create a per-bay catalogue, where we add the location of the bay within the image as extra parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Name of the Excel file (assumed to be in the same folder as the script)\n",
    "excel_filename = \"Third Journal Article Parameters.xlsx\"\n",
    "\n",
    "# Absolute path for output CSV\n",
    "csv_dst_path = os.path.join(path_data, \"info_df.csv\")\n",
    "\n",
    "# Read Excel into DataFrame\n",
    "df = pd.read_excel(excel_filename)\n",
    "df_info = df.copy()\n",
    "\n",
    "# Drop any completely empty columns\n",
    "df_info.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Build a set of available DP_<number> keys based on existing images\n",
    "available_dps = set()\n",
    "\n",
    "for folder in os.listdir(path_data):\n",
    "    folder_path = os.path.join(path_data, folder)\n",
    "    if folder.startswith(\"Output 1\") and os.path.isdir(folder_path): \n",
    "        # NOTE: It is enough to do this for the \"Output 1\" folder, since the parameters are common\n",
    "        image_files = glob.glob(os.path.join(folder_path, \"DP_*_*.png\"))\n",
    "        for image_file in image_files:\n",
    "            base_name = os.path.basename(image_file)\n",
    "            parts = base_name.split(\"_\")\n",
    "            if len(parts) >= 3 and parts[0] == \"DP\":\n",
    "                dp_number = parts[2]  # e.g., \"0005\"\n",
    "                available_dps.add(dp_number)\n",
    "\n",
    "# Create the \"DP\" column based on the 'Design point' column\n",
    "dp_column = []\n",
    "for dp in df[\"Design point\"]:\n",
    "    padded_dp = str(int(dp)).zfill(4)\n",
    "    dp_column.append(padded_dp if padded_dp in available_dps else \"NA\")\n",
    "\n",
    "# Insert the \"DP\" column as the first column\n",
    "df_info.insert(0, \"DP\", dp_column)\n",
    "\n",
    "# Rename columns to user-friendly labels (mind the gaps)\n",
    "df_info.rename(columns={\n",
    "    \"Length - No. of bays \": \"length\",\n",
    "    \"Width - No. of bays \": \"width\",\n",
    "    \"Number of Storeys\": \"height\",\n",
    "    \"Plate thickness\": \"thickness\",\n",
    "    \"Design point\": \"design_point\",\n",
    "}, inplace=True)\n",
    "\n",
    "# Save the final DataFrame as a CSV\n",
    "df_info.to_csv(csv_dst_path, index=False)\n",
    "\n",
    "print(f\"Created file: {csv_dst_path}\")\n",
    "display(df_info.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Ensure DP column is string for matching\n",
    "df_info[\"DP\"] = df_info[\"DP\"].astype(str).str.zfill(4)\n",
    "\n",
    "# Map POV letters to numbers\n",
    "POV_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "\n",
    "all_folders_dfs = []  # list to hold all folder-level DataFrames\n",
    "\n",
    "# Loop over Output folders and their image files\n",
    "folder_names = sorted([\n",
    "    f for f in os.listdir(path_data)\n",
    "    if os.path.isdir(os.path.join(path_data, f)) and f.startswith(\"Output \")\n",
    "])\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    print('[===== Folder: %s =====]' % folder_name)\n",
    "    \n",
    "    # Prepare rows for the folder's dataframe\n",
    "    rows_folder = []\n",
    "\n",
    "    folder_path = os.path.join(path_data, folder_name)\n",
    "    \n",
    "    # List of images inside each Output folder\n",
    "    image_names = [\n",
    "        filename for filename in os.listdir(folder_path)\n",
    "        if filename.endswith(\".png\") and filename.startswith(\"DP_\")\n",
    "    ]\n",
    "    \n",
    "    for i, image_name in enumerate(image_names):\n",
    "        print('Image %-5s[/%-5s]' % (i+1, len(image_names)), end='\\r')\n",
    "\n",
    "        # Parse the filename\n",
    "        match = re.match(r\"DP_([A-D])_(\\d{4})_bay_R\\d+_C\\d+_r(\\d+)_c(\\d+)\\.png\", image_name)\n",
    "        if match:\n",
    "            POV_file, DP_file, r, c = match.groups()\n",
    "        else:\n",
    "            print('ERROR: Image filename %s not parsed!' % image_name)\n",
    "            continue\n",
    "        \n",
    "        # Try to find the row in df_info which matches the image filename\n",
    "        row_info = df_info[df_info[\"DP\"] == DP_file]\n",
    "        \n",
    "        if row_info.empty:\n",
    "            print('ERROR: Image %s has no correspondance in info_df!' % image_name)\n",
    "            continue\n",
    "        else:\n",
    "            info = row_info.iloc[0]\n",
    "            rows_folder.append({\n",
    "                \"Image\": image_name,\n",
    "                \"DP\": info[\"DP\"],\n",
    "                \"length\": info[\"length\"],\n",
    "                \"width\": info[\"width\"],\n",
    "                \"height\": info[\"height\"],\n",
    "                \"thickness\": info[\"thickness\"],\n",
    "                \"POV\": POV_map[POV_file],\n",
    "                \"r\": int(r),\n",
    "                \"c\": int(c),\n",
    "                \"PGA\": info[\"PGA\"],\n",
    "                \"design_point\": info[\"design_point\"],\n",
    "                \"Hz\": info[\"Hz\"]\n",
    "            })\n",
    "\n",
    "    # Create dataframe for this folder\n",
    "    df_conditioning_vectors_folder = pd.DataFrame(rows_folder)\n",
    "\n",
    "    # Encode POV column into POV_A, POV_B, POV_C â€” D (3) becomes all zeros\n",
    "    if \"POV\" in df_conditioning_vectors_folder.columns:\n",
    "        dummies = pd.get_dummies(df_conditioning_vectors_folder[\"POV\"])\n",
    "        dummies = dummies.reindex(columns=[0, 1, 2], fill_value=0).rename(\n",
    "            columns={0: \"POV_A\", 1: \"POV_B\", 2: \"POV_C\"}\n",
    "        ).astype(\"int8\")  # Ensure 1/0 as int, not bool\n",
    "        df_conditioning_vectors_folder = pd.concat([df_conditioning_vectors_folder, dummies], axis=1)\n",
    "        df_conditioning_vectors_folder.drop(columns=[\"POV\"], inplace=True)\n",
    "\n",
    "\n",
    "    # Sort by DP, then drop all the other DP-related columns (POV is now one-hot encoded)\n",
    "    df_conditioning_vectors_folder.sort_values(by=\"DP\", inplace=True)\n",
    "    df_conditioning_vectors_folder.drop(columns=[\"DP\", \"design_point\"], inplace=True)\n",
    "    \n",
    "    display(df_conditioning_vectors_folder.head(5))\n",
    "\n",
    "    output_csv = os.path.join(path_data, f\"conditioning_vectors_{POV_file}_df.csv\")\n",
    "    df_conditioning_vectors_folder.to_csv(output_csv, index=False)\n",
    "\n",
    "    # Append to list containing all DataFrames\n",
    "    all_folders_dfs.append(df_conditioning_vectors_folder)\n",
    "\n",
    "# Create final dataframe\n",
    "df_conditioning_vectors = pd.concat(all_folders_dfs, ignore_index=True)\n",
    "print('Complete DataFrame:')\n",
    "display(df_conditioning_vectors.head(5))\n",
    "\n",
    "# Save to CSV in path_data\n",
    "output_csv = os.path.join(path_data, \"conditioning_vectors_df.csv\")\n",
    "df_conditioning_vectors.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"df_conditioning_vectors.csv written to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIBkzC0Masdx"
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sp5TGLw_IbSc",
    "outputId": "793f547c-ba0f-46fd-bf11-36a9d4e1667d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from typing import Literal, Optional\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for loading images and their associated conditioning vectors.\n",
    "\n",
    "    This dataset:\n",
    "    - Loads conditioning data from a CSV file.\n",
    "    - Optionally scales the conditioning vectors using a StandardScaler.\n",
    "    - Loads and transforms corresponding images from disk.\n",
    "\n",
    "    Attributes:\n",
    "        path_data (str): Root path containing image folders and conditioning CSV file.\n",
    "        cond (np.ndarray): Unnormalized conditioning vectors.\n",
    "        cond_n (np.ndarray): Normalized conditioning vectors (if scaling is applied).\n",
    "        image_names (List[str]): List of image file names.\n",
    "        image_paths (List[str]): Full paths to each image file.\n",
    "        scaler (StandardScaler or None): The fitted scaler (if used).\n",
    "        transform (torchvision.transforms): Transform applied to each image.\n",
    "    Args:\n",
    "        path_data (str): Root directory with image folders and conditioning file.\n",
    "        conditioning_file (str): CSV filename with \"Image\" column and conditioning variables.\n",
    "        scaler (StandardScaler, optional): Existing scaler to use when scale_mode=\"use\".\n",
    "        scale_mode (Literal[\"fit\", \"use\", \"none\"], default=\"none\"):\n",
    "            - \"fit\": Fit a new scaler to the conditioning vectors.\n",
    "            - \"use\": Use the provided `scaler` to transform the data.\n",
    "            - \"none\": Use raw conditioning vectors with no scaling.\n",
    "\n",
    "    Returns:\n",
    "        cond_n (Tensor): Normalized conditioning vector.\n",
    "        image (Tensor): Transformed image tensor [3 x 64 x 64].\n",
    "        cond (Tensor): Raw conditioning vector.\n",
    "        idx (int): Index of the sample.\n",
    "    \"\"\"    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path_data,\n",
    "        conditioning_file,\n",
    "        scaler: Optional[StandardScaler] = None,\n",
    "        scale_mode: Literal[\"fit\", \"use\", \"none\"] = \"none\"\n",
    "    ):\n",
    "        self.path_data = path_data\n",
    "\n",
    "        # Load condition DataFrame\n",
    "        df_cond = pd.read_csv(os.path.join(self.path_data, conditioning_file), index_col=False)\n",
    "        self.image_names = df_cond[\"Image\"].tolist()\n",
    "\n",
    "        # ðŸ”§ Drop Image column since it is not a conditioning variable\n",
    "        df_cond = df_cond.drop(columns=[\"Image\"])\n",
    "        \n",
    "        # ðŸ”§ Drop POV columns that are constant (e.g., POV_A, POV_B, POV_C)\n",
    "        pov_cols = [col for col in df_cond.columns if col.startswith(\"POV_\")]\n",
    "        for col in pov_cols:\n",
    "            if df_cond[col].nunique() == 1:\n",
    "                print(f\"WARNING: Dropping constant POV column: {col}\")\n",
    "                df_cond.drop(columns=[col], inplace=True)\n",
    "        \n",
    "        # Separate POV columns (do not normalize) and numeric columns (to normalize)\n",
    "        pov_cols = [col for col in df_cond.columns if col.startswith(\"POV_\")]\n",
    "        num_cols = [col for col in df_cond.columns if col not in pov_cols]\n",
    "\n",
    "        df_num = df_cond[num_cols]\n",
    "        df_pov = df_cond[pov_cols]\n",
    "        \n",
    "        # ðŸ”§ Apply scaling only to numerical part\n",
    "        if scale_mode == \"fit\":\n",
    "            self.scaler = MinMaxScaler().fit(df_num.values)\n",
    "            cond_n_num = self.scaler.transform(df_num.values)\n",
    "        elif scale_mode == \"use\" and scaler is not None:\n",
    "            self.scaler = scaler\n",
    "            cond_n_num = self.scaler.transform(df_num.values)\n",
    "        elif scale_mode == \"none\":\n",
    "            self.scaler = None\n",
    "            cond_n_num = df_num.values\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scaler setup. Use 'fit', 'use', or 'none'.\")\n",
    "        \n",
    "        # ðŸ”§ Combine scaled numeric and raw POV parts\n",
    "        cond_pov = df_pov.values\n",
    "        self.cond_n = np.hstack([cond_n_num, cond_pov]).astype(np.float32)\n",
    "        \n",
    "        # ðŸ”§ Also save the raw (unnormalized) version\n",
    "        self.cond = pd.concat([df_num, df_pov], axis=1).astype(np.float32).values\n",
    "\n",
    "        # ðŸ”§ Resize to fixed shape here\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),   \n",
    "            transforms.ToTensor()  # <--- Normalizes images to [0..1]\n",
    "        ])\n",
    "\n",
    "        # Map prefix letter to Output folder\n",
    "        self.prefix_map = {\"A\": \"Output 1\", \"B\": \"Output 2\", \"C\": \"Output 3\", \"D\": \"Output 4\"}\n",
    "\n",
    "        # ðŸ”§ Build list of full image paths\n",
    "        self.image_paths = []\n",
    "        for name in self.image_names:\n",
    "            prefix_letter = name.split(\"_\")[1]\n",
    "            folder_name = self.prefix_map.get(prefix_letter)\n",
    "            if folder_name is None:\n",
    "                raise ValueError(f\"Unknown prefix '{prefix_letter}' in image name '{name}'\")\n",
    "            image_path = os.path.join(self.path_data, folder_name, name)\n",
    "            if not os.path.exists(image_path):\n",
    "                raise FileNotFoundError(f\"Missing image file: {image_path}\")\n",
    "            self.image_paths.append(image_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cond)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image) if self.transform else transforms.ToTensor()(image)\n",
    "        # print(f\"[DEBUG] Image shape: {image.shape}\")\n",
    "\n",
    "        cond_n = torch.tensor(self.cond_n[idx], dtype=torch.float32)\n",
    "        cond = torch.tensor(self.cond[idx], dtype=torch.float32)\n",
    "\n",
    "        return cond_n, image, cond, idx  # Return idx too\n",
    "\n",
    "# Parameters\n",
    "batch_size = 256\n",
    "\n",
    "# Step 1: Create full dataset (with normalization fitted)\n",
    "dataset = ImageDataset(\n",
    "    path_data=path_data,\n",
    "    conditioning_file=\"conditioning_vectors_df.csv\",\n",
    "    scale_mode=\"fit\",\n",
    ")\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Step 2: Split dataset\n",
    "total_len = len(dataset)\n",
    "train_len = int(0.8 * total_len)\n",
    "valid_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - valid_len\n",
    "\n",
    "# Use a fixed seed for reproducibility\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "# Split\n",
    "dataset_train, dataset_valid, dataset_test = random_split(\\\n",
    "    dataset, [train_len, valid_len, test_len], generator=generator,\n",
    ")\n",
    "\n",
    "# Step 3: Create separate DataLoaders\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, generator=generator, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, generator=generator, shuffle=False)  # To see the same valid plots\n",
    "dataloader_test  = DataLoader(dataset_test,  batch_size=test_len,   generator=generator, shuffle=False)  # Test needs only 1 batch\n",
    "\n",
    "# Test batch shapes\n",
    "X_train_n_batch, y_train_batch, X_train_batch, idxs_train = next(iter(dataloader_train))\n",
    "X_valid_n_batch, y_valid_batch, X_valid_batch, idxs_valid = next(iter(dataloader_valid))\n",
    "X_test_n_batch,  y_test_batch,  X_test_batch,  idxs_test  = next(iter(dataloader_test))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Split\", \"X_n shape\", \"y shape\", \"X shape\"]\n",
    "table.add_row([\"Train\", list(X_train_n_batch.shape), list(y_train_batch.shape), list(X_train_batch.shape)])\n",
    "table.add_row([\"Valid\", list(X_valid_n_batch.shape), list(y_valid_batch.shape), list(X_valid_batch.shape)])\n",
    "table.add_row([\"Test\",  list(X_test_n_batch.shape),  list(y_test_batch.shape),  list(X_test_batch.shape)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 3 samples from a dataloader and display them\n",
    "for i in range(3):\n",
    "    cond_vec = X_train_batch[i].numpy()\n",
    "    sample_idx = idxs_train[i].item()  # idxs_train is a tensor, convert to int\n",
    "    image_name = dataset.image_names[sample_idx]\n",
    "\n",
    "    display_vector_and_image(y_train_batch[i], cond_vec, image_name=image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing visualize_sample\"\"\";\n",
    "# Get one sample from the dataset\n",
    "cond_n, image_tensor, cond_raw, idx = dataset[0]\n",
    "\n",
    "# Visualize\n",
    "visualize_sample(X_i=cond_n, y_i=image_tensor, yhat_i=image_tensor,\n",
    "    idx=idx, image_names=dataset.image_names, epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihWmjhxHbnZ3"
   },
   "source": [
    "# Decoder\n",
    "\n",
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torchview import draw_graph\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cond_dim=21,\n",
    "        img_width=64,\n",
    "        img_height=64,\n",
    "        init_channels=64,          # number of filters for the first layer\n",
    "        conv_channels=(32, 16, 8), # output channels for each upsampling layer\n",
    "        out_channels=3             # output image channels (e.g., 3 for RGB)\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # === Dimensions & configuration ===\n",
    "        self.input_dim = cond_dim           # input to the FC projection block\n",
    "        self.init_channels = init_channels  # initial feature map depth\n",
    "        self.conv_channels = conv_channels  # tuple of output channels for conv blocks\n",
    "        self.out_channels = out_channels    # final image channels\n",
    "\n",
    "        # === Normalize condition ===\n",
    "        self.cond_norm = nn.BatchNorm1d(cond_dim, affine=True)  # normalize conditions (params learnt)\n",
    "\n",
    "        # === Initial feature map size ===\n",
    "        self.n_upsamples = len(conv_channels)  # determines how much to upscale\n",
    "        self.init_width  = img_width  // (2 ** self.n_upsamples)\n",
    "        self.init_height = img_height // (2 ** self.n_upsamples)\n",
    "        fc_output_dim = self.init_channels * self.init_height * self.init_width\n",
    "\n",
    "        # === Fully connected layers to go from latent to feature map ===\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            # nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Linear(512, fc_output_dim),\n",
    "            # nn.BatchNorm1d(fc_output_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # === Transposed convolutional blocks for upsampling ===\n",
    "        conv_layers = []\n",
    "        in_ch = self.init_channels\n",
    "        for out_ch in conv_channels:\n",
    "            conv_layers += [\n",
    "                nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1),\n",
    "                # nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "            in_ch = out_ch  # update for next block\n",
    "\n",
    "        # Final output layer to desired number of channels (e.g., RGB)\n",
    "        conv_layers += [\n",
    "            nn.Conv2d(in_ch, self.out_channels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()    # <--- Normalizes images to [0..1], compatibly to DataLoade\n",
    "        ]\n",
    "        self.conv_blocks = nn.Sequential(*conv_layers)\n",
    "\n",
    "    def forward(self, cond):\n",
    "        # Normalize the condition vector\n",
    "        cond_n = self.cond_norm(cond)  # shape: (B, cond_dim)\n",
    "\n",
    "        # Project to a flattened feature map\n",
    "        x = self.fc(cond_n)  # shape: (B, init_channels * H * W)\n",
    "\n",
    "        # Reshape to image format\n",
    "        x = x.view(x.size(0), self.init_channels, self.init_height, self.init_width)  # shape: (B, C, H, W)\n",
    "\n",
    "        # Upsample to full-resolution image\n",
    "        x = self.conv_blocks(x)  # shape: (B, out_channels, img_height, img_width)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "cond_dim = X_train_batch.shape[1]\n",
    "height, width = y_train_batch.shape[2], y_train_batch.shape[3]\n",
    "out_channels = y_train_batch.shape[1]\n",
    "\n",
    "D = Decoder(\n",
    "    cond_dim=cond_dim,\n",
    "    img_width=width,\n",
    "    img_height=height,\n",
    "    init_channels=32,\n",
    "    conv_channels=(16, 8, 4),\n",
    "    out_channels=out_channels\n",
    ").to(device)\n",
    "\n",
    "X_train_sample = X_train_batch[:4].to(device)\n",
    "\n",
    "yhat_sample = D(X_train_sample)\n",
    "print(yhat_sample.shape)  # torch.Size([4, 3, height, width])\n",
    "\n",
    "# Summary\n",
    "display(summary(D, input_data=(X_train_sample,)))\n",
    "\n",
    "# Graph (to file)\n",
    "model_graph = draw_graph(D, input_data=(X_train_sample,),\n",
    "    graph_dir=\"LR\", expand_nested=True, show_shapes=True, save_graph=True, filename=\"arch_decoder\"\n",
    ")\n",
    "model_graph.visual_graph.graph_attr[\"dpi\"] = \"600\"\n",
    "model_graph.visual_graph.render(filename=\"arch_decoder\", format=\"png\", cleanup=True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZNcY-JOfOYU"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 1000\n",
    "lr = 5e-3\n",
    "\n",
    "# Instantiate models\n",
    "cond_dim = dataset[0][0].shape[0]\n",
    "\n",
    "# Sample batch to get dimensions\n",
    "X_train_n_batch, y_train_batch, X_train_batch, idxs_train = next(iter(dataloader_train))\n",
    "height, width = y_train_batch.shape[2], y_train_batch.shape[3]\n",
    "out_channels = y_train_batch.shape[1]\n",
    "\n",
    "D = Decoder(\n",
    "    cond_dim=X_train_batch.shape[1],\n",
    "    img_width=width,\n",
    "    img_height=height,\n",
    "    init_channels=128,\n",
    "    conv_channels=(64, 32, 16),\n",
    "    out_channels=out_channels\n",
    ").to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# For tracking history\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'loss_train': [],\n",
    "    'loss_valid': [],\n",
    "}\n",
    "\n",
    "# Track best validation loss\n",
    "best_loss_valid = float('inf')\n",
    "path_to_best_model = path_results + \"/best_decoder_model.pth\"\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # === Train set ===\n",
    "    D.train()\n",
    "    loss_train_epoch = 0\n",
    "\n",
    "    for i, train_batch in enumerate(tqdm(dataloader_train, desc=f\"Epoch {epoch+1}/{n_epochs}\")):\n",
    "\n",
    "        X_train_batch = train_batch[0].to(device)\n",
    "        y_train_batch = train_batch[1].to(device)\n",
    "        # Entries:\n",
    "        #   0: normalized cond, 1: image, 2: cond, 3: indexes\n",
    "\n",
    "        D.zero_grad()\n",
    "\n",
    "        yhat_train_batch = D(X_train_batch)\n",
    "        loss_train = criterion(yhat_train_batch, y_train_batch)\n",
    "\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_epoch += loss_train.item()\n",
    "\n",
    "    # === Valid set ===\n",
    "    D.eval()\n",
    "    loss_valid_epoch = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for valid_batch in dataloader_valid:\n",
    "            X_valid_batch = valid_batch[0].to(device)\n",
    "            y_valid_batch = valid_batch[1].to(device)\n",
    "            idxs_valid_batch = valid_batch[3].to(device)\n",
    "\n",
    "            yhat_valid_batch = D(X_valid_batch)\n",
    "            loss_valid = criterion(yhat_valid_batch, y_valid_batch)\n",
    "\n",
    "            loss_valid_epoch += loss_valid.item()\n",
    "\n",
    "    # Average losses per epoch\n",
    "    avg_loss_train = loss_train_epoch / len(dataloader_train)\n",
    "    avg_loss_valid = loss_valid_epoch / len(dataloader_valid)\n",
    "\n",
    "    print(f\"[===== Epoch [{epoch+1}/{n_epochs}] =====]\")\n",
    "    print(f\"  loss - train: {loss_train_epoch:-10.4f} | avg: {avg_loss_train:.4f}\")\n",
    "    print(f\"  loss - valid: {loss_valid_epoch:-10.4f} | avg: {avg_loss_valid:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if avg_loss_valid < best_loss_valid:\n",
    "        best_loss_valid = avg_loss_valid\n",
    "        torch.save(D.state_dict(), path_to_best_model)\n",
    "        print(f\"[INFO] New best model saved at epoch {epoch+1} with validation loss {best_loss_valid:.4f}\")\n",
    "    \n",
    "    # Save to history\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['loss_train'].append(avg_loss_train)\n",
    "    history['loss_valid'].append(avg_loss_valid)\n",
    "\n",
    "    # Visualize the first few samples from last batch\n",
    "    for idx in range(4):\n",
    "        idx_dataset = idxs_valid_batch[idx].item()  # switching reference of index: batch --> dataset\n",
    "        visualize_sample(X_valid_batch[idx], y_valid_batch[idx], yhat_valid_batch[idx],\n",
    "                         idx=idx_dataset, image_names=dataset.image_names, epoch=epoch)\n",
    "    \n",
    "    # Plot history at every epoch\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S01WyZZQho4V"
   },
   "source": [
    "## Results on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D.load_state_dict(torch.load(path_to_best_model))\n",
    "D.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in dataloader_test:\n",
    "        X_test_n_batch = test_batch[0].to(device)\n",
    "        y_test_batch   = test_batch[1].to(device)\n",
    "\n",
    "        yhat_test_batch = D(X_test_n_batch)\n",
    "\n",
    "        for idx in range(10):\n",
    "            visualize_sample(X_test_n_batch[idx], y_test_batch[idx], yhat_test_batch[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deSuFywrYu8K"
   },
   "outputs": [],
   "source": [
    "#EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EOF"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch_cuda",
   "language": "python",
   "name": "pytorch_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
