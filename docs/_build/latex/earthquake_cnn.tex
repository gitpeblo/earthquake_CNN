%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{earthquake\_CNN}
\date{Jul 01, 2025}
\release{0.1}
\author{Paolo Bonfini}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Data and Preprocessing}
\label{\detokenize{data:data-and-preprocessing}}\label{\detokenize{data:data-section}}\label{\detokenize{data::doc}}

\section{Images}
\label{\detokenize{data:images}}
\sphinxAtStartPar
Our data \sphinxstylestrong{images} consist of a collection of 3,421 synthetic buildings
rendered from \sphinxstylestrong{four viewpoints}, corresponding to the cardinal directions
around the structure, i.e., front, back, left, and right view.
For each building, we therefore have:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{4 input images} showing the structure from four cardinal directions

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{4 output images} visualizing the resulting stress after an earthquake, also from the same four directions

\end{itemize}

\sphinxAtStartPar
These views are captured \sphinxstylestrong{both before and after} the simulated earthquake:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The \sphinxstylestrong{pre\sphinxhyphen{}quake images} represent the building geometry

\item {} 
\sphinxAtStartPar
The \sphinxstylestrong{post\sphinxhyphen{}quake images} display stress distributions computed via finite element analysis (FEA)

\end{itemize}

\sphinxAtStartPar
The post\sphinxhyphen{}quake images use \sphinxstylestrong{color\sphinxhyphen{}coded bays} to indicate the level of
stress — higher stress regions are shown in warmer colors (e.g., red), and
lower stress in cooler tones (e.g., blue or green).


\subsection{Example pre\sphinxhyphen{}/post\sphinxhyphen{}Earthquake}
\label{\detokenize{data:example-pre-post-earthquake}}
\sphinxAtStartPar
Below is an example of one building’s input and its corresponding output after
the application of the earthquake, both from the front view:



\sphinxAtStartPar
Note that our analysis focuses only on a \sphinxstylestrong{subset} of the total bays within each
building (in the examples above, the third column of bays).
In this representation, the finite elements are shown as a mesh that subdivides
the central bays.
The mesh resolution and bay layout are consistent across all buildings,
ensuring that stress patterns can be compared between different designs.
However, they may correspond to different physical sizes.
This size and layout information is stored in accompanying metadata files
provided alongside the images (see {\hyperref[\detokenize{data:metadata}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Metadata}}}}}).

\sphinxAtStartPar
Each building image pair is therefore uniquely identified by:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the \sphinxstylestrong{building ID}

\item {} 
\sphinxAtStartPar
the \sphinxstylestrong{view direction}

\item {} 
\sphinxAtStartPar
the \sphinxstylestrong{earthquake scenario}

\item {} 
\sphinxAtStartPar
the shape of the \sphinxstylestrong{bay grid}

\end{itemize}


\section{Metadata}
\label{\detokenize{data:metadata}}\label{\detokenize{data:id1}}

\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\phantomsection\label{\detokenize{data:table-metadata}}\nobreak
\begin{tabulary}{\linewidth}[t]{TTTTTTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
ID
&\sphinxstyletheadfamily 
\sphinxAtStartPar
length
&\sphinxstyletheadfamily 
\sphinxAtStartPar
width
&\sphinxstyletheadfamily 
\sphinxAtStartPar
height
&\sphinxstyletheadfamily 
\sphinxAtStartPar
thickness
&\sphinxstyletheadfamily 
\sphinxAtStartPar
PGA
&\sphinxstyletheadfamily 
\sphinxAtStartPar
POV
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Hz
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
0001
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
B
&
\sphinxAtStartPar
5.091223
\\
\sphinxhline
\sphinxAtStartPar
0002
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
5
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
D
&
\sphinxAtStartPar
4.298888
\\
\sphinxhline
\sphinxAtStartPar
0003
&
\sphinxAtStartPar
5
&
\sphinxAtStartPar
6
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
A
&
\sphinxAtStartPar
5.398558
\\
\sphinxhline
\sphinxAtStartPar
0004
&
\sphinxAtStartPar
7
&
\sphinxAtStartPar
8
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
C
&
\sphinxAtStartPar
4.298326
\\
\sphinxhline
\sphinxAtStartPar
0005
&
\sphinxAtStartPar
8
&
\sphinxAtStartPar
9
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
B
&
\sphinxAtStartPar
3.939938
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
In addition to the images, each building\sphinxhyphen{}earthquake pair is associated with a
set of \sphinxstylestrong{metadata} describing the structural and seismic parameters.
These include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{length}, \sphinxstylestrong{width}, and \sphinxstylestrong{height} of the building (measured in number of bays)

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{wall thickness} (structural thickness of each bay)

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{PGA} (\sphinxstyleemphasis{peak ground acceleration}) — a measure of earthquake intensity

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{POV} (\sphinxstyleemphasis{point of view}) — the view direction (from one of the four sides: A, B, C, or D)

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Hz} — the dominant frequency of the ground motion

\end{itemize}


\section{Model Features}
\label{\detokenize{data:model-features}}
\sphinxAtStartPar
The metadata variables are used as \sphinxstylestrong{predictors} (\sphinxstylestrong{X}) in the machine
learning model, providing critical context about both the building’s geometry
and the seismic input.
They enable the CNN to learn how different structural configurations and
earthquake characteristics affect the resulting stress distribution.

\sphinxAtStartPar
While the metadata serve as the input features for the predictive model,
the \sphinxstylestrong{post\sphinxhyphen{}earthquake images}—which show the stress distribution—constitute
the \sphinxstylestrong{target variables} (\sphinxstylestrong{y}).
These images provide the ground truth output that the CNN is trained to predict.

\sphinxAtStartPar
In contrast, the \sphinxstylestrong{pre\sphinxhyphen{}earthquake images} are \sphinxstylestrong{not} used as inputs to the
model, but just included for preprocessing purposes  (see {\hyperref[\detokenize{data:preprocessing}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Data Preprocessing}}}}}).


\section{Data Preprocessing}
\label{\detokenize{data:data-preprocessing}}\label{\detokenize{data:preprocessing}}
\sphinxAtStartPar
Predicting the full stress map of a building as a single image is a highly
complex task, due to the high dimensionality of the output and the variability
in structural layouts.
To reduce this complexity and make the learning problem tractable, we adopt a
\sphinxstylestrong{per\sphinxhyphen{}bay} prediction strategy.
That is, rather than predicting the entire post\sphinxhyphen{}earthquake image at once, the
model is trained to predict the stress at the level of individual bays.
These local predictions can then be reassembled to reconstruct the complete
stress map.

\sphinxAtStartPar
Additionally, note that the images—like the examples shown above—often contain
various artifacts that our model is \sphinxstylestrong{not} expected to predict.
These include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{ticks} from the finite element mesh

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{labels} or annotations from the visualization tool

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{slightly irregular} or non\sphinxhyphen{}straight grid lines

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{artifacts} introduced by the earthquake simulator (e.g., white boxes)

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{inconsistent} bay sizes in pixel dimensions

\end{itemize}

\sphinxAtStartPar
These elements are removed or reduced during preprocessing: the pipeline is
specifically designed to filter out such noise and standardize the bay regions.
This ensures that the model focuses solely on learning the meaningful stress
patterns, not irrelevant visual distortions.

\sphinxAtStartPar
\textendash{}

\sphinxAtStartPar
The preprocessing happens via a Computer Vision (CV) pipeline which
automatically identifies the bays on the simpler pre\sphinxhyphen{}earthquake images, then
applies the same segmentation to the post\sphinxhyphen{}earthquake images.

\sphinxAtStartPar
The process begins with each raw input image, where we first isolate the
structural content by filtering out background pixels and cropping to the
bounding region of the building.
This ensures that the analysis focuses exclusively on the meaningful geometry.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{01_grey_DesignPointA1000}.png}
\caption{Step 1 — Filter out non\sphinxhyphen{}structural pixels and crop to the relevant building
region.}\label{\detokenize{data:id2}}\end{figure}

\sphinxAtStartPar
Next, we detect the underlying bay grid by identifying the most prominent
vertical and horizontal edges.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{02_edges_DesignPointA1000}.png}
\caption{Step 2 — Detect bay grid layout using edge detection.}\label{\detokenize{data:id3}}\end{figure}

\sphinxAtStartPar
The next steps involve extracting a template from the top\sphinxhyphen{}left cell of the
grid, which serves as a reference for the bay structure.
First, we identify the upper\sphinxhyphen{}left intersection points of the detected grid edges.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{03_intersection_DesignPointA1000}.png}
\caption{Step 3 — Identify the upper\sphinxhyphen{}left intersection points between the detected grid edges.}\label{\detokenize{data:id4}}\end{figure}

\sphinxAtStartPar
Next, a template is extracted from the top\sphinxhyphen{}left bay, using the previously
identified intersection points.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=100\sphinxpxdimen]{{04_template_DesignPointA1000}.png}
\caption{Step 4 — Extract a template bay region from the top\sphinxhyphen{}left corner of the grid.}\label{\detokenize{data:id5}}\end{figure}

\sphinxAtStartPar
Template matching is then used to locate all other bay regions that resemble
the extracted template.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{05_matches_DesignPointA1000}.png}
\caption{Step 5 — Detect all bay regions by matching the template across the image.}\label{\detokenize{data:id6}}\end{figure}

\sphinxAtStartPar
From the matched grid, we compute a bounding box that encloses the full bay layout.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{06_bbox_DesignPointA1000}.png}
\caption{Step 6 — Draw a bounding box.}\label{\detokenize{data:id7}}\end{figure}

\sphinxAtStartPar
We then draw a structured grid of rectangles, each with dimentions equal to
those of the template.
This ensures a consistent segmentation into cells of equal size.
Hower, the cell grid is only an approximation of the actual bay layout, since
the bays may not be perfectly aligned or may vary slightly in size.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{07_grid_DesignPointA1000}.png}
\caption{Step 7 — Draw a uniform grid.}\label{\detokenize{data:id8}}\end{figure}

\sphinxAtStartPar
To capture the actual content of the bays, and avoid the grid lines and ticks,
we first  slightly shrunk the grid cells.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{08_shrunk_grid_DesignPointA1000}.png}
\caption{Step 8 — Shrink all the cells.}\label{\detokenize{data:id9}}\end{figure}

\sphinxAtStartPar
\textendash{}

\sphinxAtStartPar
This grid defines the effective segmentation of the image into individual
proxy\sphinxhyphen{}bay regions, which we can then apply to the corresponding post\sphinxhyphen{}earthquake
images.
While this process does result in minor loss of edge information around each bay,
it allows us to focus on the core structural content and avoid artifacts such
as grid lines and mesh ticks.

\sphinxAtStartPar
After extraction, each bay image is resized to match the original template
shape via bicubic interpolation.
While this does \sphinxstylestrong{not} preserve the exact size of every bay in the image—since
some may vary by a few pixels—it provides a consistent target size across all
samples.
For our purposes, this caveat is acceptable, as it ensures uniformity in the
training dataset.

\sphinxAtStartPar
For the post\sphinxhyphen{}earthquake image example shown at the top, the cropped bays of
interest extracted from the bottom row appear as shown below:



\sphinxAtStartPar
To reduce high\sphinxhyphen{}frequency noise such as the grey pixels and the artifact segments
visible in the images above, a Gaussian blur is applied.



\sphinxAtStartPar
This is ultimately followed by a median filtering aimed at restoring structural
detail.



\sphinxAtStartPar
Finally, the dark bays—not used in the analysis (such as the first and last 4
columns in the pre\sphinxhyphen{}earthquake image example above)—are excluded from the dataset.

\sphinxAtStartPar
\textendash{}

\sphinxAtStartPar
The result of this pipeline is a clean, well\sphinxhyphen{}aligned dataset of labeled
bay\sphinxhyphen{}level image samples, which can be used to train a deep learning model.
This strategy allows us to frame the problem as a structured, supervised
learning task without the complexity of generating entire stress maps in one
shot.

\sphinxAtStartPar
The predicting variabels are assembled from the metadata introduced in
\DUrole{xref}{\DUrole{std}{\DUrole{std-ref}{\_metadata}}} with two minor preprocessing steps.

\sphinxAtStartPar
First, the \sphinxstylestrong{POV} feature is converted from a categorical variable to a
numerical format using \sphinxstylestrong{one\sphinxhyphen{}hot encoding} (\sphinxstylestrong{OHE}), resulting in three new
binary columns: POV\_A, POV\_B, and POV\_C.
The POV\_D category is intentionally omitted to serve as the reference class
and to avoid introducing artificial correlations in the data.

\sphinxAtStartPar
Secondly, since we are considering the images per\sphinxhyphen{}bay, we add two extra columns,
\sphinxstylestrong{r} and \sphinxstylestrong{c}, indicating the row and column indices of each bay within the
building grid, allowing the model to learn spatial relationships between
adjacent bays.

\sphinxAtStartPar
The resulting metadata table, which serves as the input features for the
machine learning model, appears as follows:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTTTTTTTTTTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
image
&\sphinxstyletheadfamily 
\sphinxAtStartPar
length
&\sphinxstyletheadfamily 
\sphinxAtStartPar
width
&\sphinxstyletheadfamily 
\sphinxAtStartPar
height
&\sphinxstyletheadfamily 
\sphinxAtStartPar
thickness
&\sphinxstyletheadfamily 
\sphinxAtStartPar
r
&\sphinxstyletheadfamily 
\sphinxAtStartPar
c
&\sphinxstyletheadfamily 
\sphinxAtStartPar
PGA
&\sphinxstyletheadfamily 
\sphinxAtStartPar
POV\_A
&\sphinxstyletheadfamily 
\sphinxAtStartPar
POV\_B
&\sphinxstyletheadfamily 
\sphinxAtStartPar
POV\_C
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Hz
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
building\_1\_A\_bay\_1
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
2
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
5.091223
\\
\sphinxhline
\sphinxAtStartPar
building\_1\_A\_bay\_2
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
2
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
5.091223
\\
\sphinxhline
\sphinxAtStartPar
building\_1\_D\_bay\_1
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
2
&
\sphinxAtStartPar
2
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
5.091223
\\
\sphinxhline
\sphinxAtStartPar
building\_5\_A\_bay\_1
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
5
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
2
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
4.298888
\\
\sphinxhline
\sphinxAtStartPar
building\_5\_B\_bay\_1
&
\sphinxAtStartPar
4
&
\sphinxAtStartPar
5
&
\sphinxAtStartPar
3
&
\sphinxAtStartPar
10
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
2
&
\sphinxAtStartPar
0.2458
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
1
&
\sphinxAtStartPar
0
&
\sphinxAtStartPar
4.298888
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}


\section{Data Summary}
\label{\detokenize{data:data-summary}}
\sphinxAtStartPar
After preprocessing and metadata integration, the dataset is organized into
two components:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{X}: the input feature matrix, including geometric and seismic metadata along with one\sphinxhyphen{}hot encoded orientation.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{y}: the target data, consisting of images representing stress distributions for individual bays.

\end{itemize}

\sphinxAtStartPar
Starting from 3,421 buildings, each captured from four different viewpoints,
we process a total of approximately 14,000 images.
From these, the pipeline extracts roughly \sphinxstylestrong{35,000 individual bay regions},
which serve as the model samples.

\sphinxAtStartPar
The following table summarizes the shapes of the input \sphinxstylestrong{X} and targets \sphinxstylestrong{y}:


\begin{savenotes}\sphinxattablestart
\sphinxthistablewithglobalstyle
\centering
\begin{tabulary}{\linewidth}[t]{TTT}
\sphinxtoprule
\sphinxstyletheadfamily 
\sphinxAtStartPar
Name
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Shape
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Data Type
\\
\sphinxmidrule
\sphinxtableatstartofbodyhook
\sphinxAtStartPar
X
&
\sphinxAtStartPar
(\textasciitilde{}35,000, 11)
&
\sphinxAtStartPar
Metadata vector
\\
\sphinxhline
\sphinxAtStartPar
y
&
\sphinxAtStartPar
(\textasciitilde{}35,000, height, width, 3)
&
\sphinxAtStartPar
RGB image (target)
\\
\sphinxbottomrule
\end{tabulary}
\sphinxtableafterendhook\par
\sphinxattableend\end{savenotes}

\sphinxstepscope


\chapter{Convolutional Neural Network Model}
\label{\detokenize{model:convolutional-neural-network-model}}\label{\detokenize{model:model-section}}\label{\detokenize{model::doc}}

\section{Data loading and batching}
\label{\detokenize{model:data-loading-and-batching}}
\sphinxAtStartPar
The training data consists of stress image patches for individual bays, paired
with a conditioning vector as described in {\hyperref[\detokenize{data:data-section}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Data and Preprocessing}}}}}.
The conditioning vectors, representing the input \sphinxstylestrong{X matrix}, include:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the building geometry (length, width, height, wall thickness)

\item {} 
\sphinxAtStartPar
seismic parameters (PGA, dominant frequency)

\item {} 
\sphinxAtStartPar
viewpoint (encoded via one\sphinxhyphen{}hot vectors)

\item {} 
\sphinxAtStartPar
bay location indices (row and column within the bay grid)

\end{itemize}

\sphinxAtStartPar
The data is handled using a custom PyTorch \sphinxtitleref{Dataset} class that:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Loads the conditioning vectors

\item {} 
\sphinxAtStartPar
Normalizes the numeric variables using a \sphinxtitleref{MinMaxScaler}

\item {} 
\sphinxAtStartPar
Preserves the one\sphinxhyphen{}hot encoded POV variables

\item {} 
\sphinxAtStartPar
Loads the corresponding post\sphinxhyphen{}earthquake RGB image from disk

\item {} 
\sphinxAtStartPar
Resizes each image to 64 × 64 and normalizes it to the {[}0, 1{]} range

\end{itemize}

\sphinxAtStartPar
The dataset is split into three subsets using an 80/10/10 split.


\section{Model architecture (PyTorch)}
\label{\detokenize{model:model-architecture-pytorch}}
\sphinxAtStartPar
Our predictive model is a \sphinxstylestrong{convolutional decoder} that generates the
post\sphinxhyphen{}earthquake stress image of a single building bay, conditioned on a vector
of input parameters.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1.000\linewidth]{{graph_decoder}.png}
\caption{Model architecture. Diagram created with \sphinxhref{https://github.com/willyfh/visualtorch}{VisualTorch}.}\label{\detokenize{model:id1}}\end{figure}

\sphinxAtStartPar
The model effectively performs a \sphinxstylestrong{regression} from the conditioning vector
to a full\sphinxhyphen{}resolution RGB image, using two main stages:

\sphinxAtStartPar
1. A \sphinxstylestrong{fully connected projection block} transforms the input conditioning vector
into a 2D feature map

\sphinxAtStartPar
2. A stack of \sphinxstylestrong{transposed convolutional layers} (a.k.a. “upsampling layers”)
upsamples this feature map to the desired image resolution

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=240\sphinxpxdimen]{{_static/model/padding_strides_transposed}.png}
\caption{Figure adapted from \sphinxhref{https://github.com/vdumoulin/conv\_arithmetic/blob/master/gif/padding\_strides\_transposed.gif}{conv\_arithmetic repository}}\label{\detokenize{model:id2}}\end{figure}

\sphinxAtStartPar
The conditioning vector is first normalized via \sphinxstylestrong{BatchNorm1d}, then passed
through two fully connected layers with ReLU activations.
The output of these layers is reshaped into a low\sphinxhyphen{}resolution 2D feature map
with a high number of channels.

\sphinxAtStartPar
This feature map is progressively upsampled by a sequence of \sphinxstylestrong{ConvTranspose2d}
layers, which increase the spatial resolution while reducing the number of channels.
Finally, a \sphinxstylestrong{Conv2d} layer with Sigmoid activation maps the upsampled features
to the desired 3\sphinxhyphen{}channel RGB output, normalized to the {[}0, 1{]} range.


\section{Training}
\label{\detokenize{model:training}}
\sphinxAtStartPar
The model is trained for 1000 epochs to minimize the difference between the
predicted stress images and the ground truth post\sphinxhyphen{}earthquake images using a
regression loss function, namely the Mean Squared Error (MSE).
Early stopping based on validation loss is applied to retain the best model checkpoint.

\sphinxAtStartPar
Training uses the Adam optimizer with a relatively low learning rate of 0.005
and a large batch size of 256.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{history}.png}
\caption{Training and validation loss over epochs, illustrating the model’s convergence.}\label{\detokenize{model:id3}}\end{figure}

\sphinxAtStartPar
Training is performed on all bays extracted from all points of view.
Because the viewpoint (POV) is included in the conditioning vector, the model
can directly learn to reproduce diverse stress patterns specific to each
perspective.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{early_prediction}.png}
\caption{Example prediction from the validation set at epoch 0, showing the ground
truth (left), model output (center), and overlay comparison (right).}\label{\detokenize{model:id4}}\end{figure}

\sphinxstepscope


\chapter{Model Predictions}
\label{\detokenize{predictions:model-predictions}}\label{\detokenize{predictions:prediction-section}}\label{\detokenize{predictions::doc}}
\sphinxAtStartPar
The model achieves a Mean Squared Error (MSE) of approximately 0.017 on the
test set, corresponding to a Root Mean Squared Error (RMSE) of about 13.0\%
relative to the normalized image intensity range {[}0, 1{]}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{predictions_bay}.png}
\caption{Example of prediction for a single bay, before assembling, showing
the ground truth (left), the model prediction (center), and an overlay
comparison (right).}\label{\detokenize{predictions:id1}}\end{figure}

\sphinxAtStartPar
Notice that the predictions are slightly pixellated, which is a common
artifact of the upsampling process in convolutional neural networks.
This is due to the model generating a low\sphinxhyphen{}resolution feature map that is
then upsampled to the full resolution, which can introduce some quantization
effects.

\sphinxAtStartPar
This effect is partially mitigated during the reconstruction of the building
from individual bays ({\hyperref[\detokenize{predictions:reconstruction}]{\sphinxcrossref{\DUrole{std}{\DUrole{std-ref}{Building Reconstruction}}}}}).


\section{Building Reconstruction}
\label{\detokenize{predictions:building-reconstruction}}\label{\detokenize{predictions:reconstruction}}
\sphinxAtStartPar
To visualize the predicted stress for an entire building, the model outputs
for each individual bay are first reshaped to match the size and layout of
the original bay template.
This reshaping happens via bicubic interpolation, which partially smooths out
the pixellated artifacts introduced during the upsampling process.

\sphinxAtStartPar
These predicted bay images are then systematically reassembled according to
their spatial positions within the building’s grid, effectively reconstructing
the full post\sphinxhyphen{}earthquake stress map of the building.

\sphinxAtStartPar
Similarly, the ground truth bay images are reshaped and arranged in the same
manner to reconstruct the ground truth building.
This is necessary because the original bays have slightly different sizes and
aspect ratios, which can lead to minor variations in the pixel dimensions of
the reconstructed images.
Reshaping all of them to a common template size allows for a direct visual
comparison between predictions and ground truth at the building level.

\sphinxAtStartPar
\textendash{}

\sphinxAtStartPar
The following images show the post\sphinxhyphen{}earthquake stress distribution reconstructed
at the building level, alongside the model prediction.
The example refers to the same building shown in \sphinxtitleref{ref:data\_section}.




\chapter{Project Overview}
\label{\detokenize{index:project-overview}}
\sphinxAtStartPar
This project focuses on simulating and predicting the effects of earthquakes
on synthetic buildings composed of bays arranged in a 3D grid of size
\sphinxstylestrong{R × C × K}, where \sphinxstylestrong{R} is the number of floors, and \sphinxstylestrong{C} and \sphinxstylestrong{K} are the
number of bays along the building’s width and depth, respectively.
Each building configuration is subjected to simulated seismic events, and the
resulting structural stress is analyzed using \sphinxstylestrong{finite element analysis (FEA)}.

\sphinxAtStartPar
This synthetic dataset is used to create a machine learning model that can
predict post\sphinxhyphen{}earthquake stress distributions based on pre\sphinxhyphen{}earthquake geometry
and loading.


\section{Objective}
\label{\detokenize{index:objective}}
\sphinxAtStartPar
The primary objective of this project is to develop a \sphinxstylestrong{convolutional neural network (CNN)}
model capable of predicting the stress experienced by each bay in the building
following an earthquake.
The model takes as input the building’s structural characteristics—such as its
geometry and bay layout—along with the seismic input parameters, including the
earthquake’s peak ground acceleration (PGA) and frequency.

\sphinxAtStartPar
By learning from the synthetic dataset generated through FEA simulations, the
CNN aims to estimate the resulting stress distribution across the building bays
with high spatial resolution.
This approach can potentially enable real\sphinxhyphen{}time assessment of structural vulnerability
without the need for computationally expensive simulations.



\renewcommand{\indexname}{Index}
\printindex
\end{document}